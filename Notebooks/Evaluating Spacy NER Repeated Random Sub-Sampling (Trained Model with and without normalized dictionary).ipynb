{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the results of Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of training (and its evaluation) will depend on how the data was split into training and testing sets. In this worksheet, we use repeated random subsampling to assess the performance of our trained model.\n",
    "\n",
    "According to [Wikipedia](https://en.wikipedia.org/wiki/Cross-validation_(statistics)):\n",
    "\n",
    ">This method, also known as Monte Carlo cross-validation,[16] creates multiple random splits of the dataset into training and validation data.[17] For each such split, the model is fit to the training data, and predictive accuracy is assessed using the validation data. The results are then averaged over the splits. The advantage of this method (over k-fold cross validation) is that the proportion of the training/validation split is not dependent on the number of iterations (folds). The disadvantage of this method is that some observations may never be selected in the validation subsample, whereas others may be selected more than once. In other words, validation subsets may overlap. This method also exhibits Monte Carlo variation, meaning that the results will vary if the analysis is repeated with different random splits.\n",
    "\n",
    "We will be dividing our data into an 80-20 split, using 80% for training and 20% for testing. This will be repeated randomly for each iteration of training to evaluate how much the training improves results on average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary modules\n",
    "\n",
    "from __future__ import unicode_literals, print_function\n",
    "import spacy\n",
    "from spacy.lang.es import Spanish \n",
    "from spacy.scorer import Scorer\n",
    "from spacy.language import GoldParse\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plac\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Tagged Data from JSON file\n",
    "with open('TaggedData_SF.json', 'r', encoding='utf-8') as fp2:\n",
    "    TAGGED_DATA = json.load(fp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy has a built-in function for evaluating a model's performance using the [command line](https://spacy.io/api/cli#evaluate), but alternatively you can define a function like the one below. It takes the NER model and examples that you input and returns several metrics:\n",
    "        - UAS (Unlabelled Attachment Score) \n",
    "        - LAS (Labelled Attachment Score)\n",
    "        - ents_p\n",
    "        - ents_r\n",
    "        - ents_f\n",
    "        - tags_acc\n",
    "        - token_acc\n",
    "\n",
    "[According](https://github.com/explosion/spaCy/issues/2405) to one of the creators of Spacy, \n",
    ">The UAS and LAS are standard metrics to evaluate dependency parsing. UAS is the proportion of tokens whose head has been correctly assigned, LAS is the proportion of tokens whose head has been correctly assigned with the right dependency label (subject, object, etc).\n",
    ">ents_p, ents_r, ents_f are the precision, recall and fscore for the NER task.\n",
    ">tags_acc is the POS tagging accuracy.\n",
    ">token_acc seems to be the precision for token segmentation.\n",
    "\n",
    "The key metrics for this task are the precision, recall and f-score.\n",
    "**Precision** (ents_p) is the ratio of correctly-labeled entities out of all the entities labeled. (True Positive/(True Positive+False Positive)).\n",
    "**Recall**  (ents_r) is the ratio of correctly-labeled entities out of all true entities (True Positive/(True Positive+False Negative)). The F-score is the mean of both values.  \n",
    "\n",
    "These metrics all appear averaged out through all the entity types (labels) and then detailed for each label in particular. We want these values to be as close as possible to 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " def evaluate(ner_model, examples):\n",
    "        scorer = Scorer()\n",
    "        for sents, ents in examples:\n",
    "            doc_gold = ner_model.make_doc(sents)\n",
    "            gold = GoldParse(doc_gold, entities=ents['entities'])\n",
    "            pred_value = ner_model(sents)\n",
    "            scorer.score(pred_value, gold)\n",
    "        return scorer.scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the Spacy model, define a blank dataframe to store the output of our different trials, and calculate the amount of data necessary for an 80-20 split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spacy Model\n",
    "nlp= spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a blank dataframe with columns for the information we are interested in\n",
    "\n",
    "columns=['ents_p', 'ents_r', 'ents_f', 'label']\n",
    "eval_data = pd.DataFrame(columns=columns)\n",
    "eval_data = eval_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326.40000000000003"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate 80% of data for an 80-20 split\n",
    "\n",
    "len(TAGGED_DATA)*0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the training loop ten times, each with a different 80-20 split, and store the evaluation statistics of our NER model in our dataframe. We are using a copy of the NLP model because we want the training to start afresh for each set of training data. Otherwise, the model would be trained on all the data including the test data, leading to the model overperforming on the tagged data compared to new samples that we are interested in tagging later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 28710.784190735434}\n",
      "Losses {'ner': 26217.361760210915}\n",
      "Losses {'ner': 25762.10888914067}\n",
      "Losses {'ner': 25750.571883825527}\n",
      "Losses {'ner': 25605.796603823735}\n",
      "Losses {'ner': 25429.72852884233}\n",
      "Losses {'ner': 25745.145906287013}\n",
      "Losses {'ner': 25202.404243156314}\n",
      "Losses {'ner': 25266.99406839907}\n",
      "Losses {'ner': 25489.240974783897}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 31591.14445352634}\n",
      "Losses {'ner': 28971.689574223412}\n",
      "Losses {'ner': 28273.77027401668}\n",
      "Losses {'ner': 28336.130817049503}\n",
      "Losses {'ner': 28210.249039787763}\n",
      "Losses {'ner': 27932.240037732292}\n",
      "Losses {'ner': 27763.095332303084}\n",
      "Losses {'ner': 27761.657864421606}\n",
      "Losses {'ner': 27966.925535529852}\n",
      "Losses {'ner': 27986.069834038615}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 26945.293095998208}\n",
      "Losses {'ner': 25167.346635711245}\n",
      "Losses {'ner': 24865.326570675505}\n",
      "Losses {'ner': 24759.969239159836}\n",
      "Losses {'ner': 24462.15672765486}\n",
      "Losses {'ner': 24161.691222325433}\n",
      "Losses {'ner': 24112.155050163157}\n",
      "Losses {'ner': 24064.27712816}\n",
      "Losses {'ner': 23956.684035614133}\n",
      "Losses {'ner': 23839.304557979107}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 27110.85079757983}\n",
      "Losses {'ner': 25542.006545636585}\n",
      "Losses {'ner': 24979.226497480387}\n",
      "Losses {'ner': 24547.429351536848}\n",
      "Losses {'ner': 24613.389862455253}\n",
      "Losses {'ner': 24512.074842367787}\n",
      "Losses {'ner': 24681.574770851526}\n",
      "Losses {'ner': 24779.593505322002}\n",
      "Losses {'ner': 24596.447332318872}\n",
      "Losses {'ner': 24318.319078240544}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 30488.85419589215}\n",
      "Losses {'ner': 28687.697905284665}\n",
      "Losses {'ner': 28125.0853675947}\n",
      "Losses {'ner': 28158.405765480653}\n",
      "Losses {'ner': 27799.292017261556}\n",
      "Losses {'ner': 27696.296528354287}\n",
      "Losses {'ner': 27807.155438090675}\n",
      "Losses {'ner': 27492.209538640454}\n",
      "Losses {'ner': 27701.541603811085}\n",
      "Losses {'ner': 27152.533492848277}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 31832.310360369545}\n",
      "Losses {'ner': 29624.760219540498}\n",
      "Losses {'ner': 28827.35449362125}\n",
      "Losses {'ner': 28888.269523585797}\n",
      "Losses {'ner': 29323.167477035196}\n",
      "Losses {'ner': 28606.358226528653}\n",
      "Losses {'ner': 29008.68169680424}\n",
      "Losses {'ner': 28562.194599561393}\n",
      "Losses {'ner': 28843.713932642713}\n",
      "Losses {'ner': 28893.85529360175}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 29413.36972112849}\n",
      "Losses {'ner': 27412.688492122692}\n",
      "Losses {'ner': 26843.842970116562}\n",
      "Losses {'ner': 26724.03263234324}\n",
      "Losses {'ner': 26401.12417769333}\n",
      "Losses {'ner': 27028.430566645227}\n",
      "Losses {'ner': 26514.723485483788}\n",
      "Losses {'ner': 26307.222000241978}\n",
      "Losses {'ner': 26294.23305862397}\n",
      "Losses {'ner': 26241.790966272354}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 30254.052561019857}\n",
      "Losses {'ner': 28162.963799256624}\n",
      "Losses {'ner': 27546.89418252615}\n",
      "Losses {'ner': 27500.149581443322}\n",
      "Losses {'ner': 26897.616367609065}\n",
      "Losses {'ner': 26974.760558665264}\n",
      "Losses {'ner': 26839.389122212306}\n",
      "Losses {'ner': 26972.785244077444}\n",
      "Losses {'ner': 27031.776955366135}\n",
      "Losses {'ner': 27015.844194456935}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 28270.271258579625}\n",
      "Losses {'ner': 26794.917620348635}\n",
      "Losses {'ner': 26116.506573714745}\n",
      "Losses {'ner': 25864.87159792958}\n",
      "Losses {'ner': 25542.15608135699}\n",
      "Losses {'ner': 25435.581236070022}\n",
      "Losses {'ner': 25549.276633552276}\n",
      "Losses {'ner': 25479.81967278011}\n",
      "Losses {'ner': 25041.12965906784}\n",
      "Losses {'ner': 25443.65072990954}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 28671.18886008404}\n",
      "Losses {'ner': 26576.080714818563}\n",
      "Losses {'ner': 26100.679036867645}\n",
      "Losses {'ner': 25881.440064884606}\n",
      "Losses {'ner': 25993.326108673704}\n",
      "Losses {'ner': 25671.08909981791}\n",
      "Losses {'ner': 25842.97500598058}\n",
      "Losses {'ner': 25603.911143779755}\n",
      "Losses {'ner': 25803.398500412703}\n",
      "Losses {'ner': 25493.54890247248}\n"
     ]
    }
   ],
   "source": [
    "# Testing how much the evaluation depends on texts included in testing data\n",
    "\n",
    "#Loop 10 times\n",
    "for x in range(0,10):\n",
    "    \n",
    "    #Batching the Tagged Data into training and evaluation data (80-20 split)\n",
    "\n",
    "    random.shuffle(TAGGED_DATA)\n",
    "    train_data = TAGGED_DATA[:326]\n",
    "    test_data = TAGGED_DATA[326:]\n",
    "\n",
    "    #Load the model to be trained (save separately, because we do not want to repeatedly retrain the same model)\n",
    "    nlp1 = deepcopy(nlp)\n",
    "    \n",
    "    #Create object for retrieving the NER pipeline component\n",
    "    ner=nlp1.get_pipe(\"ner\")\n",
    "\n",
    "    #Generate new labels for the NER component (if you wish to create new labels)\n",
    "    ner.add_label(\"OBJ\")\n",
    "    ner.add_label(\"MON\")\n",
    "    ner.add_label(\"DATE\")\n",
    "\n",
    "    #This piece of code creates a loop in which we train the model, but only for the NER component (disabling the tagger and the parser, which we are not using here).\n",
    "    with nlp1.disable_pipes('tagger','parser'):\n",
    "    #Here we resume training, alternatively you could begin_training if you are starting on a new model.\n",
    "        optimizer= nlp1.resume_training()\n",
    "    #Would need to figure this out, they are the sizes for the minibatching\n",
    "        sizes = compounding(1.0, 4.0, 1.001)\n",
    "    #This loops the training mechanism 10 times, randomly shuffling the training data and creating mini-batches from which the algorithm learns to label. Each time a batch is processed, the model is updated.\n",
    "        for itn in range(10):\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=sizes)\n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp1.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "            print(\"Losses\", losses)\n",
    "    \n",
    "    #Testing NER results of existing model on test data\n",
    "\n",
    "    results = evaluate(nlp1,test_data)\n",
    "    evaluation= dict((k, results[k]) for k in ['ents_per_type'] \n",
    "                                        if k in results)\n",
    "    \n",
    "    ev_date = [val.get('DATE') for val in evaluation.values()]\n",
    "    ev_mon= [val.get('MON') for val in evaluation.values()]\n",
    "    ev_obj= [val.get('OBJ') for val in evaluation.values()]\n",
    "    ev_org= [val.get('ORG') for val in evaluation.values()]\n",
    "    ev_per= [val.get('PER') for val in evaluation.values()]\n",
    "    ev_loc= [val.get('LOC') for val in evaluation.values()]\n",
    "    \n",
    "    dlist = list(ev_date[0].values())\n",
    "    newrow1= {'ents_p': dlist[0],'ents_r': dlist[1],'ents_f':dlist[2],'label':'DATE'}\n",
    "    \n",
    "    mlist = list(ev_mon[0].values())\n",
    "    newrow2= {'ents_p': mlist[0],'ents_r':mlist[1],'ents_f':mlist[2],'label':'MON'}\n",
    "                  \n",
    "    oblist = list(ev_obj[0].values())\n",
    "    newrow3= {'ents_p':oblist[0],'ents_r':oblist[1],'ents_f':oblist[2],'label':'OBJ'}\n",
    "                  \n",
    "    orlist = list(ev_org[0].values())\n",
    "    newrow4= {'ents_p':orlist[0],'ents_r':orlist[1],'ents_f':orlist[2],'label':'ORG'}\n",
    "                  \n",
    "    plist = list(ev_per[0].values())\n",
    "    newrow5= {'ents_p':plist[0],'ents_r':plist[1],'ents_f':plist[2],'label':'PER'}\n",
    "                  \n",
    "    llist = list(ev_loc[0].values())\n",
    "    newrow6= {'ents_p':llist[0],'ents_r':llist[1],'ents_f':llist[2],'label':'LOC'}\n",
    "                  \n",
    "    eval_data=eval_data.append(newrow1,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow2,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow3,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow4,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow5,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow6,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we print the contents of our evaluation dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ents_p     ents_r     ents_f label\n",
      "0    50.000000   5.882353  10.526316  DATE\n",
      "1    63.414634  32.098765  42.622951   MON\n",
      "2     0.000000   0.000000   0.000000   OBJ\n",
      "3    44.444444  23.529412  30.769231   ORG\n",
      "4    86.142322  80.701754  83.333333   PER\n",
      "5    80.575540  78.321678  79.432624   LOC\n",
      "6     0.000000   0.000000   0.000000  DATE\n",
      "7    64.864865  31.168831  42.105263   MON\n",
      "8     0.000000   0.000000   0.000000   OBJ\n",
      "9    15.384615   4.081633   6.451613   ORG\n",
      "10   85.520362  84.000000  84.753363   PER\n",
      "11   94.545455  75.362319  83.870968   LOC\n",
      "12  100.000000   6.666667  12.500000  DATE\n",
      "13   63.157895  58.536585  60.759494   MON\n",
      "14    0.000000   0.000000   0.000000   OBJ\n",
      "15   36.842105  15.217391  21.538462   ORG\n",
      "16   87.301587  88.000000  87.649402   PER\n",
      "17   82.170543  76.811594  79.400749   LOC\n",
      "18    0.000000   0.000000   0.000000  DATE\n",
      "19   47.058824  35.164835  40.251572   MON\n",
      "20    0.000000   0.000000   0.000000   OBJ\n",
      "21   48.000000  18.461538  26.666667   ORG\n",
      "22   85.865724  85.263158  85.563380   PER\n",
      "23   84.939759  84.431138  84.684685   LOC\n",
      "24  100.000000   5.000000   9.523810  DATE\n",
      "25   75.000000  60.937500  67.241379   MON\n",
      "26   33.333333   1.162791   2.247191   OBJ\n",
      "27   26.470588  17.307692  20.930233   ORG\n",
      "28   90.157480  86.090226  88.076923   PER\n",
      "29   84.892086  67.816092  75.399361   LOC\n",
      "30   50.000000  13.043478  20.689655  DATE\n",
      "31   51.724138  37.500000  43.478261   MON\n",
      "32    0.000000   0.000000   0.000000   OBJ\n",
      "33    4.000000   2.272727   2.898551   ORG\n",
      "34   88.500000  83.098592  85.714286   PER\n",
      "35   85.039370  73.972603  79.120879   LOC\n",
      "36    0.000000   0.000000   0.000000  DATE\n",
      "37   55.932203  52.380952  54.098361   MON\n",
      "38  100.000000   7.608696  14.141414   OBJ\n",
      "39   64.285714  40.000000  49.315068   ORG\n",
      "40   90.086207  88.936170  89.507495   PER\n",
      "41   83.571429  82.978723  83.274021   LOC\n",
      "42    0.000000   0.000000   0.000000  DATE\n",
      "43   90.000000  64.285714  75.000000   MON\n",
      "44  100.000000   1.265823   2.500000   OBJ\n",
      "45    7.692308   3.773585   5.063291   ORG\n",
      "46   87.619048  84.792627  86.182670   PER\n",
      "47   85.148515  71.666667  77.828054   LOC\n",
      "48   50.000000  13.333333  21.052632  DATE\n",
      "49   64.516129  48.780488  55.555556   MON\n",
      "50    0.000000   0.000000   0.000000   OBJ\n",
      "51   34.285714  24.000000  28.235294   ORG\n",
      "52   90.400000  84.014870  87.090559   PER\n",
      "53   91.891892  75.977654  83.180428   LOC\n",
      "54   66.666667  14.285714  23.529412  DATE\n",
      "55   80.000000  66.666667  72.727273   MON\n",
      "56    0.000000   0.000000   0.000000   OBJ\n",
      "57   47.826087  21.153846  29.333333   ORG\n",
      "58   81.773399  81.773399  81.773399   PER\n",
      "59   79.861111  79.310345  79.584775   LOC\n"
     ]
    }
   ],
   "source": [
    "print(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure mean and standard deviation of f, p and r scores for each label \n",
    "a = eval_data.groupby('label').agg({'ents_f':['mean','std'],'ents_p':['mean','std'],'ents_r':['mean','std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_f</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_p</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>9.782182</td>\n",
       "      <td>9.578643</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>40.253824</td>\n",
       "      <td>5.821155</td>\n",
       "      <td>5.936515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>80.577654</td>\n",
       "      <td>3.017314</td>\n",
       "      <td>85.263570</td>\n",
       "      <td>4.642661</td>\n",
       "      <td>76.664881</td>\n",
       "      <td>4.973763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MON</th>\n",
       "      <td>55.384011</td>\n",
       "      <td>13.193679</td>\n",
       "      <td>65.566869</td>\n",
       "      <td>13.052479</td>\n",
       "      <td>48.752034</td>\n",
       "      <td>13.813612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBJ</th>\n",
       "      <td>1.888861</td>\n",
       "      <td>4.417157</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>41.722185</td>\n",
       "      <td>1.003731</td>\n",
       "      <td>2.375146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>22.120174</td>\n",
       "      <td>14.267794</td>\n",
       "      <td>32.923158</td>\n",
       "      <td>19.451804</td>\n",
       "      <td>16.979782</td>\n",
       "      <td>11.556657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>85.964481</td>\n",
       "      <td>2.293672</td>\n",
       "      <td>87.336613</td>\n",
       "      <td>2.670296</td>\n",
       "      <td>84.667080</td>\n",
       "      <td>2.563800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ents_f                ents_p                ents_r           \n",
       "            mean        std       mean        std       mean        std\n",
       "label                                                                  \n",
       "DATE    9.782182   9.578643  41.666667  40.253824   5.821155   5.936515\n",
       "LOC    80.577654   3.017314  85.263570   4.642661  76.664881   4.973763\n",
       "MON    55.384011  13.193679  65.566869  13.052479  48.752034  13.813612\n",
       "OBJ     1.888861   4.417157  23.333333  41.722185   1.003731   2.375146\n",
       "ORG    22.120174  14.267794  32.923158  19.451804  16.979782  11.556657\n",
       "PER    85.964481   2.293672  87.336613   2.670296  84.667080   2.563800"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluating Spelling Normalization\n",
    "\n",
    "We can apply the evaluation above to a model trained with text whose spelling has been normalized, thus evaluating whether the inclusion of a normalization dictionary improves training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Norm Exceptions from JSON file\n",
    "with open('normalizeddict.json', 'r', encoding='utf-8') as fp3:\n",
    "    NORM_EXCEPTIONS = json.load(fp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and add pipeline component that updates .norm attribute\n",
    "\n",
    "def add_custom_norms(doc):\n",
    "    for token in doc:\n",
    "        if token.text in NORM_EXCEPTIONS:\n",
    "            token.norm_ = NORM_EXCEPTIONS[token.text]\n",
    "    return doc\n",
    "\n",
    "#Add component to the pipeline\n",
    "\n",
    "nlp.add_pipe(add_custom_norms, first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a new blank dataframe with columns for the information we are interested in\n",
    "\n",
    "columns=['ents_p', 'ents_r', 'ents_f', 'label']\n",
    "eval_data2 = pd.DataFrame(columns=columns)\n",
    "eval_data2 = eval_data2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 29499.62115381894}\n",
      "Losses {'ner': 27432.198336651258}\n",
      "Losses {'ner': 27237.476574885826}\n",
      "Losses {'ner': 26886.309408007888}\n",
      "Losses {'ner': 26540.757857780347}\n",
      "Losses {'ner': 26545.37359688431}\n",
      "Losses {'ner': 26574.1013068147}\n",
      "Losses {'ner': 26679.740034505725}\n",
      "Losses {'ner': 26516.571289405227}\n",
      "Losses {'ner': 26684.599556565285}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 30651.302070253238}\n",
      "Losses {'ner': 28284.725300171824}\n",
      "Losses {'ner': 27811.04373792749}\n",
      "Losses {'ner': 27858.08806299469}\n",
      "Losses {'ner': 27718.562570926966}\n",
      "Losses {'ner': 27328.900965396315}\n",
      "Losses {'ner': 27189.881448478438}\n",
      "Losses {'ner': 27317.36295453459}\n",
      "Losses {'ner': 27218.52796754241}\n",
      "Losses {'ner': 27065.22095376253}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 29590.74765747037}\n",
      "Losses {'ner': 27184.64154662579}\n",
      "Losses {'ner': 27026.793694191245}\n",
      "Losses {'ner': 26454.55213338224}\n",
      "Losses {'ner': 26839.336028540452}\n",
      "Losses {'ner': 26708.574336301535}\n",
      "Losses {'ner': 26650.113122107927}\n",
      "Losses {'ner': 26635.132207155228}\n",
      "Losses {'ner': 26199.49300429225}\n",
      "Losses {'ner': 26226.21255362034}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 28093.531449958275}\n",
      "Losses {'ner': 25667.964437861654}\n",
      "Losses {'ner': 24951.78715877945}\n",
      "Losses {'ner': 25100.753037386166}\n",
      "Losses {'ner': 24785.410763391832}\n",
      "Losses {'ner': 24760.63866879698}\n",
      "Losses {'ner': 24289.866849032464}\n",
      "Losses {'ner': 24400.87175379321}\n",
      "Losses {'ner': 24482.260458946228}\n",
      "Losses {'ner': 24565.933971002698}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 28332.016745980498}\n",
      "Losses {'ner': 26362.2281262184}\n",
      "Losses {'ner': 25635.542517440506}\n",
      "Losses {'ner': 25117.322425551873}\n",
      "Losses {'ner': 25136.405352118192}\n",
      "Losses {'ner': 25244.448437670246}\n",
      "Losses {'ner': 24999.708883602172}\n",
      "Losses {'ner': 25051.532636642456}\n",
      "Losses {'ner': 24823.247329860926}\n",
      "Losses {'ner': 24896.657667689025}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 28390.664817206565}\n",
      "Losses {'ner': 26001.15853855208}\n",
      "Losses {'ner': 25853.95808242492}\n",
      "Losses {'ner': 25646.67148854825}\n",
      "Losses {'ner': 25621.01740635198}\n",
      "Losses {'ner': 25310.714385457337}\n",
      "Losses {'ner': 25641.85621431656}\n",
      "Losses {'ner': 25141.601619463414}\n",
      "Losses {'ner': 25471.13282689452}\n",
      "Losses {'ner': 25402.038847267628}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 28857.829207675437}\n",
      "Losses {'ner': 26427.575190555293}\n",
      "Losses {'ner': 25773.047303230134}\n",
      "Losses {'ner': 25860.04211168643}\n",
      "Losses {'ner': 25870.547863037034}\n",
      "Losses {'ner': 25445.04180361796}\n",
      "Losses {'ner': 25652.979458531365}\n",
      "Losses {'ner': 25652.355613194406}\n",
      "Losses {'ner': 25368.51256494224}\n",
      "Losses {'ner': 25482.41212736629}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 31183.07043193781}\n",
      "Losses {'ner': 28938.966911083655}\n",
      "Losses {'ner': 28314.097444169314}\n",
      "Losses {'ner': 27981.325828345012}\n",
      "Losses {'ner': 27896.63830166764}\n",
      "Losses {'ner': 27506.291575556505}\n",
      "Losses {'ner': 27805.07676478289}\n",
      "Losses {'ner': 27623.085354603827}\n",
      "Losses {'ner': 27410.957109078765}\n",
      "Losses {'ner': 27565.289154559374}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 29698.50474952518}\n",
      "Losses {'ner': 28100.42544671885}\n",
      "Losses {'ner': 27684.143731447766}\n",
      "Losses {'ner': 27413.299044790547}\n",
      "Losses {'ner': 27221.78061976153}\n",
      "Losses {'ner': 27076.371534661856}\n",
      "Losses {'ner': 26987.433071333915}\n",
      "Losses {'ner': 27206.584793627262}\n",
      "Losses {'ner': 26959.954725861317}\n",
      "Losses {'ner': 27405.67962694168}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 27282.973104532}\n",
      "Losses {'ner': 25546.693975118553}\n",
      "Losses {'ner': 24631.723043808382}\n",
      "Losses {'ner': 24399.073844784987}\n",
      "Losses {'ner': 24632.41723647827}\n",
      "Losses {'ner': 24773.259103098884}\n",
      "Losses {'ner': 24214.003735827282}\n",
      "Losses {'ner': 24327.542434114963}\n",
      "Losses {'ner': 23951.511757960543}\n",
      "Losses {'ner': 24057.59735112358}\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Model trained with EMS dictionary\n",
    "\n",
    "#Loop 10 times\n",
    "for x in range(0,10):\n",
    "    \n",
    "    random.shuffle(TAGGED_DATA)\n",
    "    train_data = TAGGED_DATA[:326]\n",
    "    test_data = TAGGED_DATA[326:]\n",
    "    \n",
    "    #Load the model to be trained\n",
    "    nlp2 = deepcopy(nlp)\n",
    "    \n",
    "    #Create object for retrieving the NER pipeline component\n",
    "    ner=nlp2.get_pipe(\"ner\")\n",
    "\n",
    "    #Generate new labels for the NER component (if you wish to create new labels)\n",
    "    ner.add_label(\"OBJ\")\n",
    "    ner.add_label(\"MON\")\n",
    "    ner.add_label(\"DATE\")\n",
    "\n",
    "    #This piece of code creates a loop in which we train the model, but only for the NER component (disabling the tagger and the parser, which we are not using here).\n",
    "    with nlp2.disable_pipes('tagger','parser'):\n",
    "    #Here we resume training, alternatively you could begin_training if you are starting on a new model.\n",
    "        optimizer= nlp2.resume_training()\n",
    "    #Would need to figure this out, they are the sizes for the minibatching\n",
    "        sizes = compounding(1.0, 4.0, 1.001)\n",
    "    #This loops the training mechanism 10 times, randomly shuffling the training data and creating mini-batches from which the algorithm learns to label. Each time a batch is processed, the model is updated.\n",
    "        for itn in range(10):\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=sizes)\n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp2.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "            print(\"Losses\", losses)\n",
    "   \n",
    " #Testing NER results of existing model on test data\n",
    "\n",
    "    results = evaluate(nlp2,test_data)\n",
    "    evaluation= dict((k, results[k]) for k in ['ents_per_type'] \n",
    "                                        if k in results)\n",
    "    \n",
    "    ev_date = [val.get('DATE') for val in evaluation.values()]\n",
    "    ev_mon= [val.get('MON') for val in evaluation.values()]\n",
    "    ev_obj= [val.get('OBJ') for val in evaluation.values()]\n",
    "    ev_org= [val.get('ORG') for val in evaluation.values()]\n",
    "    ev_per= [val.get('PER') for val in evaluation.values()]\n",
    "    ev_loc= [val.get('LOC') for val in evaluation.values()]\n",
    "    \n",
    "    dlist = list(ev_date[0].values())\n",
    "    newrow1= {'ents_p': dlist[0],'ents_r': dlist[1],'ents_f':dlist[2],'label':'DATE'}\n",
    "    \n",
    "    mlist = list(ev_mon[0].values())\n",
    "    newrow2= {'ents_p': mlist[0],'ents_r':mlist[1],'ents_f':mlist[2],'label':'MON'}\n",
    "                  \n",
    "    oblist = list(ev_obj[0].values())\n",
    "    newrow3= {'ents_p':oblist[0],'ents_r':oblist[1],'ents_f':oblist[2],'label':'OBJ'}\n",
    "                  \n",
    "    orlist = list(ev_org[0].values())\n",
    "    newrow4= {'ents_p':orlist[0],'ents_r':orlist[1],'ents_f':orlist[2],'label':'ORG'}\n",
    "                  \n",
    "    plist = list(ev_per[0].values())\n",
    "    newrow5= {'ents_p':plist[0],'ents_r':plist[1],'ents_f':plist[2],'label':'PER'}\n",
    "                  \n",
    "    llist = list(ev_loc[0].values())\n",
    "    newrow6= {'ents_p':llist[0],'ents_r':llist[1],'ents_f':llist[2],'label':'LOC'}\n",
    "                  \n",
    "    eval_data2=eval_data2.append(newrow1,ignore_index=True)\n",
    "    eval_data2=eval_data2.append(newrow2,ignore_index=True)\n",
    "    eval_data2=eval_data2.append(newrow3,ignore_index=True)\n",
    "    eval_data2=eval_data2.append(newrow4,ignore_index=True)\n",
    "    eval_data2=eval_data2.append(newrow5,ignore_index=True)\n",
    "    eval_data2=eval_data2.append(newrow6,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= eval_data2.groupby('label').agg({'ents_f':['mean','std'],'ents_p':['mean','std'],'ents_r':['mean','std']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we print the statistics for the training with (b) and without (a) spelling normalization. As can be seen, there is a slight improvement on most measurements (as well as a reduction in variability) when we normalize spelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_f</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_p</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>9.782182</td>\n",
       "      <td>9.578643</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>40.253824</td>\n",
       "      <td>5.821155</td>\n",
       "      <td>5.936515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>80.577654</td>\n",
       "      <td>3.017314</td>\n",
       "      <td>85.263570</td>\n",
       "      <td>4.642661</td>\n",
       "      <td>76.664881</td>\n",
       "      <td>4.973763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MON</th>\n",
       "      <td>55.384011</td>\n",
       "      <td>13.193679</td>\n",
       "      <td>65.566869</td>\n",
       "      <td>13.052479</td>\n",
       "      <td>48.752034</td>\n",
       "      <td>13.813612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBJ</th>\n",
       "      <td>1.888861</td>\n",
       "      <td>4.417157</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>41.722185</td>\n",
       "      <td>1.003731</td>\n",
       "      <td>2.375146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>22.120174</td>\n",
       "      <td>14.267794</td>\n",
       "      <td>32.923158</td>\n",
       "      <td>19.451804</td>\n",
       "      <td>16.979782</td>\n",
       "      <td>11.556657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>85.964481</td>\n",
       "      <td>2.293672</td>\n",
       "      <td>87.336613</td>\n",
       "      <td>2.670296</td>\n",
       "      <td>84.667080</td>\n",
       "      <td>2.563800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ents_f                ents_p                ents_r           \n",
       "            mean        std       mean        std       mean        std\n",
       "label                                                                  \n",
       "DATE    9.782182   9.578643  41.666667  40.253824   5.821155   5.936515\n",
       "LOC    80.577654   3.017314  85.263570   4.642661  76.664881   4.973763\n",
       "MON    55.384011  13.193679  65.566869  13.052479  48.752034  13.813612\n",
       "OBJ     1.888861   4.417157  23.333333  41.722185   1.003731   2.375146\n",
       "ORG    22.120174  14.267794  32.923158  19.451804  16.979782  11.556657\n",
       "PER    85.964481   2.293672  87.336613   2.670296  84.667080   2.563800"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_f</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_p</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>6.181599</td>\n",
       "      <td>9.238110</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>33.379598</td>\n",
       "      <td>3.616384</td>\n",
       "      <td>5.377218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>82.013233</td>\n",
       "      <td>2.651031</td>\n",
       "      <td>86.110284</td>\n",
       "      <td>4.359660</td>\n",
       "      <td>78.437365</td>\n",
       "      <td>3.290363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MON</th>\n",
       "      <td>51.947078</td>\n",
       "      <td>9.837542</td>\n",
       "      <td>70.758458</td>\n",
       "      <td>12.463683</td>\n",
       "      <td>42.015463</td>\n",
       "      <td>10.894793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBJ</th>\n",
       "      <td>2.933807</td>\n",
       "      <td>2.513359</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>41.163630</td>\n",
       "      <td>1.525103</td>\n",
       "      <td>1.316534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>22.247787</td>\n",
       "      <td>8.778882</td>\n",
       "      <td>31.986232</td>\n",
       "      <td>12.151958</td>\n",
       "      <td>17.145127</td>\n",
       "      <td>6.982109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>86.558603</td>\n",
       "      <td>2.209405</td>\n",
       "      <td>88.364413</td>\n",
       "      <td>2.650517</td>\n",
       "      <td>84.850763</td>\n",
       "      <td>2.290407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ents_f               ents_p                ents_r           \n",
       "            mean       std       mean        std       mean        std\n",
       "label                                                                 \n",
       "DATE    6.181599  9.238110  21.666667  33.379598   3.616384   5.377218\n",
       "LOC    82.013233  2.651031  86.110284   4.359660  78.437365   3.290363\n",
       "MON    51.947078  9.837542  70.758458  12.463683  42.015463  10.894793\n",
       "OBJ     2.933807  2.513359  48.333333  41.163630   1.525103   1.316534\n",
       "ORG    22.247787  8.778882  31.986232  12.151958  17.145127   6.982109\n",
       "PER    86.558603  2.209405  88.364413   2.650517  84.850763   2.290407"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
