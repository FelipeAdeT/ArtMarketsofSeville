{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the results of Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import spacy\n",
    "from spacy.lang.es import Spanish \n",
    "from spacy import displacy\n",
    "from spacy.tokens import Doc\n",
    "from collections import defaultdict, Counter\n",
    "from spacy.attrs import ORTH\n",
    "from spacy.scorer import Scorer\n",
    "from spacy.language import GoldParse\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plac\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "#nlp = Spanish().from_disk(\"Documents/Research/NPL/SevillianPaintersNPL/EM Spanish Model/Trained_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
    "    try:\n",
    "        training_data = []\n",
    "        lines=[]\n",
    "        with open(dataturks_JSON_FilePath, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            data = json.loads(line)\n",
    "            text = data['content']\n",
    "            entities = []\n",
    "            for annotation in data['annotation']:\n",
    "                #only a single point in text annotation.\n",
    "                point = annotation['points'][0]\n",
    "                labels = annotation['label']\n",
    "                # handle both list of labels or a single label.\n",
    "                if not isinstance(labels, list):\n",
    "                    labels = [labels]\n",
    "\n",
    "                for label in labels:\n",
    "                    #dataturks indices are both inclusive [start, end] but spacy is not [start, end)\n",
    "                    entities.append((point['start'], point['end'] + 1 ,label))\n",
    "\n",
    "\n",
    "            training_data.append((text, {\"entities\" : entities}))\n",
    "\n",
    "        return training_data\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Unable to process \" + dataturks_JSON_FilePath + \"\\n\" + \"error = \" + str(e))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Dataturks to Spacy Format\n",
    "\n",
    "TAGGED_DATA = convert_dataturks_to_spacy(\"/Users/Felipe/Documents/Research/NPL/SevillianPaintersNPL/seville painters test 2-3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spacy Model\n",
    "\n",
    "nlp = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing how much the evaluation depends on texts included in testing data\n",
    "\n",
    "#Generate empty dictionary for storing evaluation results of different trials\n",
    "d = {}\n",
    "\n",
    "#Loop 101 times\n",
    "for x in range(0,101):\n",
    "    \n",
    "    #Batching the Tagged Data into training and evaluation data (80-20)\n",
    "\n",
    "    random.shuffle(TAGGED_DATA)\n",
    "    train_data = TAGGED_DATA[:326]\n",
    "    test_data = TAGGED_DATA[326:]\n",
    "\n",
    "    #Testing NER results of existing model on test data\n",
    "\n",
    "    def evaluate(ner_model, examples):\n",
    "        scorer = Scorer()\n",
    "        for sents, ents in examples:\n",
    "            doc_gold = ner_model.make_doc(sents)\n",
    "            gold = GoldParse(doc_gold, entities=ents['entities'])\n",
    "            pred_value = ner_model(sents)\n",
    "            scorer.score(pred_value, gold)\n",
    "        return scorer.scores\n",
    "\n",
    "    results = evaluate(nlp,test_data)\n",
    "    d[x] = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      uas  las     ents_p     ents_r     ents_f  \\\n",
      "DATE  0.0  0.0  48.702595  41.924399  45.060018   \n",
      "LOC   0.0  0.0  48.702595  41.924399  45.060018   \n",
      "MISC  0.0  0.0  48.702595  41.924399  45.060018   \n",
      "MON   0.0  0.0  48.702595  41.924399  45.060018   \n",
      "OBJ   0.0  0.0  48.702595  41.924399  45.060018   \n",
      "ORG   0.0  0.0  48.702595  41.924399  45.060018   \n",
      "PER   0.0  0.0  48.702595  41.924399  45.060018   \n",
      "\n",
      "                                          ents_per_type  tags_acc  token_acc  \\\n",
      "DATE                     {'p': 0.0, 'r': 0.0, 'f': 0.0}       0.0      100.0   \n",
      "LOC   {'p': 46.012269938650306, 'r': 49.342105263157...       0.0      100.0   \n",
      "MISC                     {'p': 0.0, 'r': 0.0, 'f': 0.0}       0.0      100.0   \n",
      "MON                      {'p': 0.0, 'r': 0.0, 'f': 0.0}       0.0      100.0   \n",
      "OBJ                      {'p': 0.0, 'r': 0.0, 'f': 0.0}       0.0      100.0   \n",
      "ORG   {'p': 7.142857142857142, 'r': 2.38095238095238...       0.0      100.0   \n",
      "PER   {'p': 57.33788395904437, 'r': 73.6842105263157...       0.0      100.0   \n",
      "\n",
      "      textcat_score  textcats_per_cat  \n",
      "DATE            0.0               NaN  \n",
      "LOC             0.0               NaN  \n",
      "MISC            0.0               NaN  \n",
      "MON             0.0               NaN  \n",
      "OBJ             0.0               NaN  \n",
      "ORG             0.0               NaN  \n",
      "PER             0.0               NaN  \n"
     ]
    }
   ],
   "source": [
    "print(d[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['ents_p', 'ents_r', 'ents_f', 'label','trial']\n",
    "eval_data = pd.DataFrame(columns=columns)\n",
    "eval_data = eval_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ents_p, ents_r, ents_f, label, trial]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract information from dictionary (f, p and r scores for each label within each trial) and save it into a dataframe\n",
    "for x in d:\n",
    "    ev_date= d[x].loc['DATE','ents_per_type']\n",
    "    ev_loc= d[x].loc['LOC','ents_per_type']\n",
    "    ev_misc= d[x].loc['MISC','ents_per_type']\n",
    "    ev_mon= d[x].loc['MON','ents_per_type']\n",
    "    ev_obj= d[x].loc['OBJ','ents_per_type']\n",
    "    ev_org= d[x].loc['ORG','ents_per_type']\n",
    "    ev_per= d[x].loc['PER','ents_per_type']\n",
    "    newrow1={'ents_p':ev_date['p'],'ents_r':ev_date['r'],'ents_f':ev_date['f'],'label':'DATE','trial':x}\n",
    "    newrow2={'ents_p':ev_loc['p'],'ents_r':ev_loc['r'],'ents_f':ev_loc['f'],'label':'LOC','trial':x}\n",
    "    newrow3={'ents_p':ev_misc['p'],'ents_r':ev_misc['r'],'ents_f':ev_misc['f'],'label':'MISC','trial':x}\n",
    "    newrow4={'ents_p':ev_mon['p'],'ents_r':ev_mon['r'],'ents_f':ev_mon['f'],'label':'MON','trial':x}\n",
    "    newrow5={'ents_p':ev_obj['p'],'ents_r':ev_obj['r'],'ents_f':ev_obj['f'],'label':'OBJ','trial':x}\n",
    "    newrow6={'ents_p':ev_org['p'],'ents_r':ev_org['r'],'ents_f':ev_org['f'],'label':'ORG','trial':x}\n",
    "    newrow7={'ents_p':ev_per['p'],'ents_r':ev_per['r'],'ents_f':ev_per['f'],'label':'PER','trial':x}\n",
    "    eval_data=eval_data.append(newrow1,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow2,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow3,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow4,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow5,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow6,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow7,ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ents_p     ents_r     ents_f label trial\n",
      "0     0.000000   0.000000   0.000000  DATE     0\n",
      "1    39.408867  48.192771  43.360434   LOC     0\n",
      "2     0.000000   0.000000   0.000000  MISC     0\n",
      "3     0.000000   0.000000   0.000000   MON     0\n",
      "4     0.000000   0.000000   0.000000   OBJ     0\n",
      "5     9.090909   1.369863   2.380952   ORG     0\n",
      "6    45.682451  73.542601  56.357388   PER     0\n",
      "7     0.000000   0.000000   0.000000  DATE     1\n",
      "8    46.153846  50.704225  48.322148   LOC     1\n",
      "9     0.000000   0.000000   0.000000  MISC     1\n",
      "10    0.000000   0.000000   0.000000   MON     1\n",
      "11    0.000000   0.000000   0.000000   OBJ     1\n",
      "12   15.384615   4.545455   7.017544   ORG     1\n",
      "13   62.737643  81.280788  70.815451   PER     1\n",
      "14    0.000000   0.000000   0.000000  DATE     2\n",
      "15   36.416185  41.447368  38.769231   LOC     2\n",
      "16    0.000000   0.000000   0.000000  MISC     2\n",
      "17    0.000000   0.000000   0.000000   MON     2\n",
      "18    0.000000   0.000000   0.000000   OBJ     2\n",
      "19   10.000000   1.639344   2.816901   ORG     2\n",
      "20   54.076087  75.665399  63.074485   PER     2\n",
      "21    0.000000   0.000000   0.000000  DATE     3\n",
      "22   46.012270  49.342105  47.619048   LOC     3\n",
      "23    0.000000   0.000000   0.000000  MISC     3\n",
      "24    0.000000   0.000000   0.000000   MON     3\n",
      "25    0.000000   0.000000   0.000000   OBJ     3\n",
      "26    7.142857   2.380952   3.571429   ORG     3\n",
      "27   57.337884  73.684211  64.491363   PER     3\n",
      "28    0.000000   0.000000   0.000000  DATE     4\n",
      "29   41.447368  47.727273  44.366197   LOC     4\n",
      "..         ...        ...        ...   ...   ...\n",
      "677   8.333333   1.562500   2.631579   ORG    96\n",
      "678  49.608355  73.076923  59.097978   PER    96\n",
      "679   0.000000   0.000000   0.000000  DATE    97\n",
      "680  42.446043  39.864865  41.114983   LOC    97\n",
      "681   0.000000   0.000000   0.000000  MISC    97\n",
      "682   0.000000   0.000000   0.000000   MON    97\n",
      "683   0.000000   0.000000   0.000000   OBJ    97\n",
      "684  12.500000   1.886792   3.278689   ORG    97\n",
      "685  56.047198  79.497908  65.743945   PER    97\n",
      "686   0.000000   0.000000   0.000000  DATE    98\n",
      "687  38.805970  38.235294  38.518519   LOC    98\n",
      "688   0.000000   0.000000   0.000000  MISC    98\n",
      "689   0.000000   0.000000   0.000000   MON    98\n",
      "690   0.000000   0.000000   0.000000   OBJ    98\n",
      "691   0.000000   0.000000   0.000000   ORG    98\n",
      "692  52.215190  75.342466  61.682243   PER    98\n",
      "693   0.000000   0.000000   0.000000  DATE    99\n",
      "694  37.755102  46.250000  41.573034   LOC    99\n",
      "695   0.000000   0.000000   0.000000  MISC    99\n",
      "696   0.000000   0.000000   0.000000   MON    99\n",
      "697   0.000000   0.000000   0.000000   OBJ    99\n",
      "698   7.692308   1.724138   2.816901   ORG    99\n",
      "699  46.900270  68.503937  55.680000   PER    99\n",
      "700   0.000000   0.000000   0.000000  DATE   100\n",
      "701  41.706161  52.380952  46.437995   LOC   100\n",
      "702   0.000000   0.000000   0.000000  MISC   100\n",
      "703   0.000000   0.000000   0.000000   MON   100\n",
      "704   0.000000   0.000000   0.000000   OBJ   100\n",
      "705  11.111111   1.449275   2.564103   ORG   100\n",
      "706  60.579710  82.283465  69.782972   PER   100\n",
      "\n",
      "[707 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_f</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_p</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>44.520979</td>\n",
       "      <td>4.405790</td>\n",
       "      <td>42.088666</td>\n",
       "      <td>5.309654</td>\n",
       "      <td>47.555381</td>\n",
       "      <td>4.680152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MON</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBJ</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>2.744431</td>\n",
       "      <td>2.505632</td>\n",
       "      <td>8.923374</td>\n",
       "      <td>8.278483</td>\n",
       "      <td>1.668712</td>\n",
       "      <td>1.578833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>62.982444</td>\n",
       "      <td>4.325562</td>\n",
       "      <td>54.139124</td>\n",
       "      <td>4.884477</td>\n",
       "      <td>75.441766</td>\n",
       "      <td>3.493916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ents_f               ents_p               ents_r          \n",
       "            mean       std       mean       std       mean       std\n",
       "label                                                               \n",
       "DATE    0.000000  0.000000   0.000000  0.000000   0.000000  0.000000\n",
       "LOC    44.520979  4.405790  42.088666  5.309654  47.555381  4.680152\n",
       "MISC    0.000000  0.000000   0.000000  0.000000   0.000000  0.000000\n",
       "MON     0.000000  0.000000   0.000000  0.000000   0.000000  0.000000\n",
       "OBJ     0.000000  0.000000   0.000000  0.000000   0.000000  0.000000\n",
       "ORG     2.744431  2.505632   8.923374  8.278483   1.668712  1.578833\n",
       "PER    62.982444  4.325562  54.139124  4.884477  75.441766  3.493916"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Measure mean and standard deviation of f, p and r scores for each label \n",
    "eval_data.groupby('label').agg({'ents_f':['mean','std'],'ents_p':['mean','std'],'ents_r':['mean','std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
